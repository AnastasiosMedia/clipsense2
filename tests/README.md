# ClipSense E2E Tests

This directory contains end-to-end tests for the ClipSense MVP application.

## Overview

The E2E tests verify the complete video processing pipeline using synthetic media generated by FFmpeg. No external media files are required.

## Test Assets

The tests use synthetic media generated by FFmpeg:

- **clip1.mp4**: 10-second color bars with timecode overlay and 1kHz sine wave
- **clip2.mp4**: 12-second solid blue background with moving red box and 1kHz sine wave
- **music.wav**: 60-second pink noise normalized to approximately -18 LUFS

## Running Tests Locally

### Prerequisites

1. **FFmpeg installed**: Required for both asset generation and video processing

   ```bash
   # macOS
   brew install ffmpeg

   # Ubuntu/Debian
   sudo apt install ffmpeg

   # Windows
   # Download from https://ffmpeg.org/download.html
   ```

2. **Python dependencies**: Install test requirements

   ```bash
   cd worker
   pip install -r requirements.txt
   ```

3. **Node.js dependencies**: Install frontend dependencies
   ```bash
   pnpm install
   ```

### Quick Start

```bash
# Short E2E test suite (20s outputs)
pnpm run test:e2e

# Long E2E test suite (60s outputs)
pnpm run test:long

# All E2E tests (short + long)
pnpm run test:e2e:all

# Parallel test execution
pnpm run test:parallel:short  # Run short tests in parallel
pnpm run test:parallel:long   # Run long tests in parallel

# Asset verification
pnpm run test:verify:assets   # Verify asset hashes
pnpm run test:generate:hashes # Generate current hashes

# Or run steps individually
pnpm run test:e2e:assets  # Generate test assets
pytest -m short -v        # Run short tests
pytest -m long -v         # Run long tests
pytest -n auto            # Run all tests in parallel
```

### Manual Test Execution

1. **Generate test assets**:

   ```bash
   # Using Python script (recommended)
   python tests/e2e_assets.py

   # Or using bash script
   bash tests/e2e_assets.sh
   ```

2. **Start the worker** (in a separate terminal):

   ```bash
   cd worker
   WORKER_PORT=8123 python main.py
   ```

3. **Run tests**:
   ```bash
   pytest tests/ -v
   ```

## Test Structure

### Files

- `conftest.py` - Pytest configuration and fixtures
- `test_autocut_e2e.py` - Main E2E test suite
- `e2e_assets.py` - Python script for generating test assets
- `e2e_assets.sh` - Bash script for generating test assets (fallback)

### Test Cases

1. **Worker Health Tests**

   - `/ping` endpoint functionality
   - `/health` endpoint with FFmpeg verification
   - System status validation

2. **Auto-Cut Processing Tests**

   - Complete video processing pipeline
   - Output file generation and validation
   - Duration accuracy (within ±1 second of target)
   - Processing metrics validation

3. **Error Handling Tests**

   - Missing file handling
   - Invalid input validation
   - Graceful error responses

4. **Output Quality Tests**
   - Video codec and resolution validation
   - Audio codec and sample rate validation
   - File integrity checks

## Test Configuration

### Environment Variables

- `WORKER_PORT` - Port for the worker (default: 8123)
- `PYTEST_TIMEOUT` - Test timeout in seconds (default: 300)

### Test Data

- **Input**: 2 video clips (10s + 12s) + 1 music file (60s)
- **Target Duration**: 20 seconds
- **Expected Output**: ~20-second highlight video
- **Tolerance**: ±1 second duration accuracy

## Debugging Failed Tests

### Check Test Assets

```bash
# Verify assets were generated
ls -la tests/media/

# Check asset properties
ffprobe tests/media/clip1.mp4
ffprobe tests/media/clip2.mp4
ffprobe tests/media/music.wav
```

### Inspect Output Files

```bash
# Check output video properties
ffprobe tests/.tmp/test_*/highlight_final.mp4

# Play output video (if GUI available)
ffplay tests/.tmp/test_*/highlight_final.mp4
```

### Worker Logs

```bash
# Check worker logs
tail -f worker.log

# Or run worker with verbose output
cd worker
python main.py --port 8123
```

### Test Artifacts

Failed tests preserve artifacts in `tests/.tmp/`:

- Generated output videos
- Temporary processing files
- Error logs

## CI/CD Integration

### GitHub Actions

Tests run automatically on:

- Push to `main` or `develop` branches
- Pull requests to `main` or `develop`

**Matrix Testing**:

- **OS**: Ubuntu Latest, macOS Latest
- **Python**: 3.11
- **Node.js**: 20

### Local CI Simulation

```bash
# Simulate CI environment
export WORKER_PORT=8123
pnpm run test:e2e:ci
```

## Performance Expectations

### Typical Test Duration

- **Asset Generation**: 10-30 seconds
- **Worker Startup**: 5-10 seconds
- **Video Processing**: 30-120 seconds
- **Total Test Suite**: 2-5 minutes

### Resource Usage

- **Disk Space**: ~50MB for test assets + output files
- **Memory**: ~200-500MB during processing
- **CPU**: High during video processing (FFmpeg intensive)

## Troubleshooting

### Common Issues

1. **FFmpeg not found**

   ```bash
   # Verify installation
   ffmpeg -version
   ffprobe -version
   ```

2. **Port already in use**

   ```bash
   # Use different port
   WORKER_PORT=8124 pytest tests/ -v
   ```

3. **Test assets missing**

   ```bash
   # Regenerate assets
   pnpm run test:e2e:assets
   ```

4. **Worker startup fails**

   ```bash
   # Check FFmpeg availability
   python -c "from worker.ffmpeg_checker import FFmpegChecker; print(FFmpegChecker.check_ffmpeg_availability())"
   ```

5. **Tests timeout**
   ```bash
   # Increase timeout
   pytest tests/ -v --timeout=600
   ```

### Debug Mode

```bash
# Run with debug output
pytest tests/ -v -s --tb=long

# Run specific test
pytest tests/test_autocut_e2e.py::TestAutoCutE2E::test_autocut_processing -v -s
```

## Contributing

### Deterministic Testing

- **Fixed Seeds**: Pink noise uses `seed=424242` for reproducibility
- **Byte-Stable Outputs**: FFmpeg flags ensure consistent file generation
- **No Timestamps**: Metadata stripped to avoid time-based variations
- **Parallel-Safe**: Unique temp directories per test run (`run_{PID}_{PORT}`)

### Temp Directory Management

- **Parallel-Safe**: Each test run gets unique temp directory
- **Format**: `tests/.tmp/run_{PID}_{WORKER_PORT}/`
- **Worker Integration**: Uses `CLIPSENSE_TMP_DIR` environment variable
- **Cleanup**: Automatic cleanup after test completion

### Test Markers

- `@pytest.mark.short` - Quick E2E tests (≤20s outputs)
- `@pytest.mark.long` - Slower E2E tests (≥60s outputs)

### Parallel Execution

- **pytest-xdist**: Run tests in parallel across CPU cores
- **Isolation**: Each worker gets unique temp directory
- **Performance**: Significantly faster test execution
- **Usage**: `pytest -n auto` or `pnpm run test:parallel`

### Asset Verification

- **Hash Checking**: SHA256 verification of generated assets
- **Deterministic**: Ensures byte-stable outputs across runs
- **CI Integration**: Automatic verification in test pipeline
- **Usage**: `pnpm run test:verify:assets`

### CI/CD Features

- **Weekly Long Tests**: Automated long test suite every Sunday
- **Caching**: Python and pnpm dependency caching
- **Artifact Management**: Minimal artifact upload on failure
- **Parallel Matrix**: Ubuntu + macOS testing

## Contributing

When adding new tests:

1. Follow the existing naming convention
2. Add appropriate docstrings
3. Include both positive and negative test cases
4. Update this README if adding new test categories
5. Ensure tests are deterministic and don't depend on external resources
6. Use appropriate markers for test duration
7. Respect parallel-safe temp directory patterns
